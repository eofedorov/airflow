{
  "doc_key": "adr-2024-08-pgbouncer",
  "title": "ADR-2024-08: PgBouncer Transaction Pooling for Postgres",
  "doc_type": "adr",
  "created_at": "2024-08-22",
  "content": "# ADR-2024-08: Introduce PgBouncer Transaction Pooling for Postgres\n\n## Status\nAccepted (2024-08-22)\n\n## Context\nWe run multiple services (checkout-service, cart-service, search-api, payment-gateway) and background workers. Each component previously maintained its own connection pool directly to the Postgres primary. Under load, the total number of open connections became the sum of:\n- web pods * (workers per pod) * (pool size)\n- plus workers (indexing, refunds, webhook processing)\n\nThis regularly exceeded Postgres capacity and caused incidents:\n- `FATAL: sorry, too many clients already`\n- cascading timeouts as pools blocked\n- elevated p95 latency due to connection churn\n\nScaling Postgres `max_connections` is not a good primary fix because it increases memory usage per backend and can degrade performance.\n\n## Decision\nIntroduce PgBouncer as a connection pooler in **transaction pooling** mode for application traffic.\n\n- All application services must connect via PgBouncer (`:6432`) by default.\n- Direct connections to Postgres primary (`:5432`) are reserved for:\n  - migrations (alembic)\n  - admin/debugging sessions\n  - explicitly approved exceptions\n\n## Technical design\n### PgBouncer mode\nWe choose `pool_mode = transaction` because:\n- it maximizes reuse of server connections\n- it handles high concurrency better than session pooling\n\n### Core settings (prod baseline)\n```ini\npool_mode = transaction\nmax_client_conn = 5000\ndefault_pool_size = 50\nreserve_pool_size = 10\nserver_idle_timeout = 60\nquery_wait_timeout = 120\nignore_startup_parameters = extra_float_digits\n```\n\n### Service configuration\nFastAPI (SQLAlchemy 2.0 + psycopg):\n- Use `DATABASE_URL` pointing at PgBouncer:\n  - `postgresql+psycopg://app:***@pgbouncer.ecommerce-prod.svc:6432/ecommerce`\n- Keep client-side pool small to avoid “pool-on-pool” issues:\n  - `DB_POOL_SIZE=10`\n  - `DB_MAX_OVERFLOW=5`\n\nNode payment-gateway (`pg`):\n- `max: 20` in pool config (client-side)\n- Ensure `statement_timeout` and `query_timeout` are set per transaction (cannot rely on session state)\n\n### Compatibility constraints\nTransaction pooling breaks session-level assumptions:\n- prepared statements across transactions\n- temp tables that persist across requests\n- session settings (`SET ROLE`, `SET search_path`) must be applied each transaction\n\nPolicy:\n- If a service requires session features, it must document why and request an exception. Exception traffic must be rate-limited.\n\n### Monitoring\nWe will monitor:\n- PgBouncer `cl_waiting` and `sv_active`\n- Postgres `numbackends`\n- Error rate: `timeout waiting for server connection`\n\n## Consequences\n### Positive\n- Dramatically reduces Postgres backend count.\n- More stable p95 latency under spikes.\n- Clear operational boundary: PgBouncer absorbs connection churn.\n\n### Negative / risks\n- Adds a critical component; PgBouncer outage affects all services.\n- Some libraries “quietly” rely on session features; bugs can appear after migration.\n- Migrations must bypass PgBouncer; otherwise failures can be confusing.\n\n## Rollout plan\n1. Deploy PgBouncer into staging and validate with one service (cart-service).\n2. Migrate services one-by-one, keeping the ability to revert quickly.\n3. Add a deploy checklist item: ensure `DATABASE_URL` points to PgBouncer.\n4. Add runbook and alerting for connection exhaustion incidents (see RB-2024-11).\n\n## Edge cases and notes\n- If PgBouncer is saturated, clients will queue and latency will rise even if Postgres is healthy. Watch `query_wait_timeout`.\n- If a deploy accidentally points a service at Postgres primary, connection count spikes quickly; treat as SEV-2 if it threatens `max_connections`.\n- Alembic migrations run as Kubernetes jobs; these jobs must use primary Postgres and must not share the app’s PgBouncer URL.\n\n## Alternatives considered\n1. **Increase Postgres max_connections**: rejected; higher memory footprint and still vulnerable to bursts.\n2. **Service-by-service pool tuning** only: rejected; error-prone and easy to regress in deploys.\n3. **Use a managed Postgres proxy**: deferred; would reduce ops but adds vendor coupling.\n\n## Validation\nSuccess criteria after rollout:\n- Postgres `numbackends` stays < 300 during peak.\n- No sustained `too many clients` errors.\n- PgBouncer `cl_waiting` remains near 0 under normal load.\n\nOperational drill:\n- Temporarily scale checkout-service web pods up by 2x in staging and confirm Postgres connections remain stable.\n- Simulate PgBouncer restart and verify services recover without manual intervention (connection retry logic must exist).\n\n## Related documents\n- RB-2024-11 Postgres connection exhaustion\n- CL-2025-09 Production deploy checklist (verify DB endpoints)",
  "language": "en"
}